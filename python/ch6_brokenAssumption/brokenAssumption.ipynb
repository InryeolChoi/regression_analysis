{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가정의 파괴\n",
    "> 회귀분석의 4가지 가정이 깨졌을 때 할 수 있는 것\n",
    "\n",
    "* 회귀분석의 기본 가정은 모델의 신뢰성을 높이기 위해 중요하다. \n",
    "\n",
    "* 이러한 가정이 깨졌을 때, 다양한 방법으로 문제를 해결할 수 있다. \n",
    "\n",
    "* 다음은 가정이 깨졌을 때 사용할 수 있는 방법들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 변수변환 - 로그변환\n",
    "\n",
    "회귀분석의 가정 중 하나인 등분산성(잔차의 분산이 일정해야 한다)이 깨졌을 때, 로그변환을 사용하여 이를 해결할 수 있다.\n",
    "\n",
    "로그변환을 통해 종속 변수의 분포를 변형하고 등분산성을 개선할 수 있다.\n",
    "\n",
    "변환 전의 회귀모형:\n",
    "$$\n",
    "\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n",
    "$$\n",
    "\n",
    "여기서 $\\mathbf{Y}$는 종속 변수 벡터, $\\mathbf{X}$는 독립 변수 행렬, $\\boldsymbol{\\beta}$는 회귀 계수 벡터, $\\boldsymbol{\\epsilon}$은 오차 벡터이다.\n",
    "\n",
    "로그변환 후의 회귀모형:\n",
    "$$\n",
    "\\log(\\mathbf{Y}) = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n",
    "$$\n",
    "\n",
    "이 변환을 통해 오차의 분산이 일정해지고 등분산성을 만족할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WLS와 GLS\n",
    "WLS와 GLS는 회귀모형에서 가정이 깨졌을 때 유용한 방법이다. \n",
    "\n",
    "특히 WLS는 비정상적인 분산을 조정하고, GLS는 공분산 구조를 모델링하여 문제를 해결한다.\n",
    "\n",
    "### WLS (가중 최소제곱법)\n",
    "WLS는 가중치를 부여하여 오차의 분산을 조정하는 방법이다. \n",
    "\n",
    "WLS에서 $\\mathbf{W}$는 각 관측값의 가중치 행렬이다. \n",
    "\n",
    "가중 최소제곱법을 사용하여 회귀계수 $\\boldsymbol{\\beta}$를 추정하는 방법은 다음과 같다:\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{WLS}} = (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W} \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "여기서 $\\mathbf{W}$는 대각선 성분이 관측값의 가중치를 포함하는 대각 행렬이다.\n",
    "\n",
    "### GLS (일반화 최소제곱법)\n",
    "GLS는 공분산 행렬이 알려진 경우 사용된다. \n",
    "\n",
    "공분산 행렬 $\\mathbf{\\Omega}$를 사용하여 회귀계수 $\\boldsymbol{\\beta}$를 추정하는 방법은 다음과 같다:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{GLS}} = (\\mathbf{X}^T \\mathbf{\\Omega}^{-1} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{\\Omega}^{-1} \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "여기서 $\\mathbf{\\Omega}$는 오차의 공분산 행렬이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 2단계 추정 + WLS\n",
    "2단계 추정은 도구 변수를 사용하여 가중치를 추정하고, 이를 바탕으로 WLS를 수행하는 방법이다. \n",
    "\n",
    "이 방법은 다음과 같은 절차로 진행된다:\n",
    "\n",
    "### 1단계 : 2단계 추정\n",
    "도구 변수를 사용하여 회귀계수를 추정하고, 이를 통해 예측된 가중치 $\\hat{\\mathbf{W}}$를 추정한다. \n",
    "\n",
    "도구 변수 $\\mathbf{Z}$를 사용하여 첫 번째 단계 회귀모형을 설정한다:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{Z} \\boldsymbol{\\Gamma} + \\mathbf{U}\n",
    "$$\n",
    "\n",
    "여기서 $\\mathbf{Z}$는 도구 변수 행렬, $\\boldsymbol{\\Gamma}$는 도구 변수에 대한 회귀계수, $\\mathbf{U}$는 오차 항이다. 이 모형을 통해 $\\mathbf{X}$를 예측하고, 그 예측값을 $\\hat{\\mathbf{X}}$로 나타낸다:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{X}} = \\mathbf{Z} \\hat{\\boldsymbol{\\Gamma}}\n",
    "$$\n",
    "\n",
    "이 예측값 $\\hat{\\mathbf{X}}$를 사용하여 가중치 $\\hat{\\mathbf{W}}$를 추정할 수 있다. 가중치는 다음과 같이 계산된다:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{W}} = \\text{diag}\\left(\\frac{1}{\\text{Var}(\\hat{X}_i)}\\right)\n",
    "$$\n",
    "\n",
    "여기서 $\\text{Var}(\\hat{X}_i)$는 각 예측된 독립 변수의 분산이다.\n",
    "\n",
    "### 2단계 : WLS 적용\n",
    "\n",
    "예측된 가중치 $\\hat{\\mathbf{W}}$를 사용하여 WLS를 수행하고 회귀계수 $\\boldsymbol{\\beta}$를 추정한다. WLS 회귀 모형은 다음과 같다:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{WLS}} = (\\mathbf{X}^T \\hat{\\mathbf{W}} \\mathbf{X})^{-1} \\mathbf{X}^T \\hat{\\mathbf{W}} \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "여기서 $\\hat{\\mathbf{W}}$는 1단계에서 추정된 가중치 행렬이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 변수변환 - delta rule\n",
    "\n",
    "델타 룰(Delta Method)은 변수 변환을 통해 회귀 분석에서 오차의 분산을 조정하는 방법이다. \n",
    "\n",
    "이 방법은 변환된 변수의 분산을 추정하는 데 유용하다. 델타 룰은 일반적으로 다음과 같은 절차를 따른다:\n",
    "\n",
    "### delta rule이란?\n",
    "변환된 변수의 함수가 미분 가능한 경우, 델타 룰을 사용하여 오차의 분산을 추정할 수 있다. \n",
    "\n",
    "델타 룰은 다음과 같은 수식으로 표현된다. 변환 함수 $g(\\cdot)$가 있을 때, 함수 $Y = g(X)$의 분산은 다음과 같이 근사할 수 있다:\n",
    "\n",
    "$$\n",
    "\\text{Var}(g(X)) \\approx \\left(\\frac{dg(X)}{dX}\\right)^2 \\text{Var}(X)\n",
    "$$\n",
    "\n",
    "여기서 $\\frac{dg(X)}{dX}$는 함수 $g(\\cdot)$의 미분값이다. 이 식은 변환 함수에 따른 오차의 분산을 근사하는 데 사용된다.\n",
    "\n",
    "### delta rule의 활용\n",
    "2단계: 변수 변환을 통해 오차 분산의 구조를 조정할 수 있다.\n",
    "\n",
    "예를 들어, 종속 변수 $Y$에 대해 로그 변환을 적용하면 다음과 같은 모형을 얻을 수 있다:\n",
    "$$\n",
    "\\log(Y_i) = \\beta_0 + \\beta_1 X_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "이 경우, 델타 룰을 적용하여 $\\log(Y_i)$의 분산을 다음과 같이 근사할 수 있다:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\log(Y_i)) \\approx \\left(\\frac{1}{Y_i}\\right)^2 \\text{Var}(Y_i)\n",
    "$$\n",
    "\n",
    "### delta rule의 특징\n",
    "이 변환은 종속 변수의 분산이 등분산성을 만족하도록 조정할 수 있다.\n",
    "\n",
    "그러나 이 방법에도 단점은 있다.\n",
    "\n",
    "- **해석의 어려움**: 변환된 변수의 해석이 직관적이지 않을 수 있다. 예를 들어, 로그 변환된 결과는 원본 데이터와 직접적으로 비교하기 어려운 경우가 많다.\n",
    "\n",
    "- **변환의 필요성**: 변환이 모든 경우에 적합하지 않을 수 있으며, 데이터에 따라 다른 변환이 필요할 수 있다.\n",
    "\n",
    "- **모형의 단순화**: 변환이 모형을 단순화하는 데 기여할 수 있지만, 복잡한 관계를 단순화할 때 중요한 정보가 손실될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 변수변환의 특징과 한계\n",
    "변수변환은 회귀모형의 가정을 만족시키기 위해 유용하지만, 몇 가지 한계가 있다. \n",
    "\n",
    "1. 변환 후에도 원래 변수의 해석이 어려워질 수 있으며, 모델의 해석 가능성이 감소할 수 있다. \n",
    "\n",
    "2. 모든 데이터에서 변환이 항상 적절한 것은 아니며, 데이터의 성격에 따라 변환이 오히려 모형의 성능을 악화시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중공선성 문제\n",
    "> 가정이 파괴된 또 하나의 문제로 다중공선성 문제가 있다.\n",
    "\n",
    "## 1. 다중공선성 문제\n",
    "다중공선성은 독립 변수들 간의 높은 상관관계로 인해 회귀분석 모형의 해석이 어려워지는 문제이다. \n",
    "\n",
    "증상으로는 회귀계수의 불안정성, 표준 오차의 증가 등이 있으며, 이는 모형의 예측 정확도에 악영향을 미칠 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 문제 발견 방법\n",
    "다중공선성을 찾기 위해 EDA(탐색적 데이터 분석)를 실시하며, 공선성 지표를 사용하는 방법이 있다. 대표적인 지표는 다음과 같다:\n",
    "\n",
    "- **Tolerance**: 각 독립 변수가 다른 독립 변수들에 의해 얼마나 설명되는지를 나타내는 지표이다. 낮은 값은 높은 다중공선성을 의미한다.\n",
    "\n",
    "- **VIF (Variance Inflation Factor)**: VIF는 각 독립 변수의 분산이 전체 모형에서 얼마나 부풀려졌는지를 측정한다. VIF가 높은 경우, 높은 다중공선성을 나타낸다.\n",
    "\n",
    "VIF는 다음과 같이 계산된다:\n",
    "$$\n",
    "\\text{VIF}_i = \\frac{1}{1 - R_i^2}\n",
    "$$\n",
    "\n",
    "여기서 $R_i^2$는 독립 변수 $X_i$를 다른 변수들로 회귀 분석했을 때의 결정계수이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 해결방안 - 변수제거\n",
    "* 다중공선성을 완화하기 위해 모델에서 특정 독립 변수를 제거하는 과정\n",
    "\n",
    "* Adjusted $R^2$, AIC, BIC 등을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 해결방안 - 주성분회귀\n",
    "\n",
    "주성분회귀는 다음과 같은 두 단계로 진행된다:\n",
    "\n",
    "1. **주성분 분석(PCA)**: 독립 변수들 간의 상관관계를 제거하기 위해 원본 데이터에서 주성분을 추출한다. \n",
    "\n",
    "* 주성분은 원본 변수들의 선형 결합으로 생성되며, 데이터의 분산을 최대한 설명하는 축을 따른다.\n",
    "\n",
    "2. **회귀 분석**: 추출된 주성분을 사용하여 회귀 모델을 적합한다. \n",
    "\n",
    "* 이 단계에서는 주성분들이 독립 변수로 사용되며, 이들 주성분을 통해 종속 변수를 예측한다.\n",
    "\n",
    "### 주성분회귀 절차\n",
    "\n",
    "1. **데이터 표준화**: 원본 데이터 $\\mathbf{X}$를 평균이 0이고 표준편차가 1인 표준 정규 분포로 변환한다.\n",
    "   $$\n",
    "   \\tilde{\\mathbf{X}} = \\frac{\\mathbf{X} - \\bar{\\mathbf{X}}}{\\sigma_{\\mathbf{X}}}\n",
    "   $$\n",
    "\n",
    "2. **주성분 분석(PCA)**: 표준화된 데이터에서 주성분을 추출한다. \n",
    "\n",
    "- 주성분들은 데이터의 분산을 최대한 설명하는 새로운 축을 형성한다. \n",
    "\n",
    "- 주성분 $\\mathbf{Z}$는 다음과 같이 표현된다:\n",
    "    $$\n",
    "    \\mathbf{Z} = \\mathbf{X} \\mathbf{P}\n",
    "    $$\n",
    "\n",
    "- 여기서 $\\mathbf{P}$는 주성분의 로딩 벡터를 포함하는 행렬이다.\n",
    "\n",
    "3. **회귀 분석**: 주성분을 독립 변수로 사용하여 회귀 분석을 수행한다. \n",
    "\n",
    "- 주성분 회귀 모형은 다음과 같이 표현된다:\n",
    "\n",
    "    $$\n",
    "    \\mathbf{Y} = \\mathbf{Z} \\boldsymbol{\\beta}_{\\text{PCR}} + \\epsilon\n",
    "    $$\n",
    "\n",
    "- 여기서 $\\boldsymbol{\\beta}_{\\text{PCR}}$는 주성분 회귀계수 벡터이다.\n",
    "\n",
    "4. **주성분 선택**: 모든 주성분을 사용하지 않고, 설명된 분산의 비율에 따라 적절한 개수의 주성분을 선택한다.\n",
    "\n",
    "- 선택된 주성분들만을 사용하여 최종 회귀 모형을 적합한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 해결방안 - 벌점화 회귀\n",
    "\n",
    "벌점화 회귀(Penalized Regression)는 다중공선성 문제를 해결하고 모델의 복잡도를 조절하기 위해 회귀 계수에 벌점(penalty)을 부과하는 방법이다. \n",
    "\n",
    "주요 벌점화 회귀 기법에는 릿지 회귀(Ridge Regression)와 라쏘 회귀(Lasso Regression)가 있다. \n",
    "\n",
    "이들 방법은 회귀계수를 추정할 때 모델의 복잡도를 조절하여 과적합(overfitting)을 방지하고, 다중공선성을 완화하는 데 도움을 준다.\n",
    "\n",
    "### 릿지 회귀 (Ridge Regression)\n",
    "\n",
    "릿지 회귀는 회귀계수에 L2 노름의 제곱을 벌점으로 추가하여 회귀계수를 추정한다. \n",
    "\n",
    "이 방법은 모든 회귀계수를 작게 만드는 데 중점을 둔다.\n",
    "\n",
    "1. **회귀 모형**: 릿지 회귀는 다음과 같은 형태의 회귀 모형을 사용한다:\n",
    "   $$\n",
    "   \\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. **벌점화 회귀계수 추정**: 릿지 회귀에서는 다음과 같은 손실 함수를 최소화하여 회귀계수를 추정한다:\n",
    "   $$\n",
    "   \\hat{\\boldsymbol{\\beta}}_{\\text{Ridge}} = \\arg \\min_{\\boldsymbol{\\beta}} \\left[ \\| \\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta} \\|^2 + \\lambda \\| \\boldsymbol{\\beta} \\|^2 \\right]\n",
    "   $$\n",
    "   여기서 $\\lambda$는 벌점의 강도를 조절하는 하이퍼파라미터로, 모델의 복잡도와 일반화 능력을 조절한다. \n",
    "   \n",
    "   $ \\boldsymbol{\\beta}^2$는 L2 노름의 제곱을 나타내며, 이는 모든 회귀계수를 작게 만들도록 유도한다.\n",
    "\n",
    "### 라쏘 회귀 (Lasso Regression)\n",
    "\n",
    "라쏘 회귀는 회귀계수에 L1 노름을 벌점으로 추가하여 회귀계수를 추정한다. 이 방법은 일부 회귀계수를 0으로 만들며, 변수 선택의 효과를 제공한다.\n",
    "\n",
    "1. **회귀 모형**: 라쏘 회귀는 릿지 회귀와 같은 기본 회귀 모형을 사용한다:\n",
    "   $$\n",
    "   \\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. **벌점화 회귀계수 추정**: 라쏘 회귀에서는 다음과 같은 손실 함수를 최소화하여 회귀계수를 추정한다:\n",
    "   $$\n",
    "   \\hat{\\boldsymbol{\\beta}}_{\\text{Lasso}} = \\arg \\min_{\\boldsymbol{\\beta}} \\left[ \\| \\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta} \\|^2 + \\lambda \\| \\boldsymbol{\\beta} \\|_1 \\right]\n",
    "   $$\n",
    "   여기서 $\\lambda$는 벌점의 강도를 조절하는 하이퍼파라미터로, 모델의 복잡도와 일반화 능력을 조절한다. $boldsymbol{\\beta}_1$는 L1 노름을 나타내며, 이는 일부 회귀계수를 0으로 만들도록 유도한다.\n",
    "\n",
    "### 벌점화 회귀의 장점과 단점\n",
    "\n",
    "- **장점**:\n",
    "  - **다중공선성 완화**: 릿지 회귀와 라쏘 회귀는 다중공선성 문제를 완화하여 회귀계수의 추정을 안정화할 수 있다.\n",
    "  - **과적합 방지**: 벌점은 모델의 복잡도를 조절하여 과적합을 방지한다.\n",
    "  - **변수 선택**: 라쏘 회귀는 자동으로 변수를 선택하므로 모델의 해석력을 높일 수 있다.\n",
    "\n",
    "- **단점**:\n",
    "  - **벌점의 선택**: $\\lambda$의 적절한 값을 선택하는 것이 중요한데, 이를 위해 교차검증 등의 추가적인 과정이 필요하다.\n",
    "  - **해석의 어려움**: 벌점화 회귀의 경우, 변수 선택 및 회귀계수 해석이 어려울 수 있다. 특히 라쏘 회귀에서는 일부 회귀계수가 0이 되어 변수 선택이 이루어지지만, 이로 인해 변수의 해석이 복잡할 수 있다.\n",
    "\n",
    "벌점화 회귀는 다중공선성 문제를 해결하고 모델의 일반화 능력을 향상시키는 유용한 방법이다. 하지만 벌점의 선택 및 해석에 주의하여 적절하게 적용해야 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
